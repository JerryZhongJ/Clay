# 概览

## 想法
这个项目尝试去构建一个有自主性的、持续存在的AI助手。

我觉得LLM模型的对话的交互方式让AI太被动了。用户去激活LLM，LLM便活跃一段时间。即便是各种agent，即便它们具有plan的能力，能够规划、制定todo，也只是让延长了活跃时间。一方面，LLM不会即时反应，除非你发送prompt，或者打断它。另一方面，它的长期记忆依然很差。

现在也有很多基于llm的实时对话模型，有很多ai vtuber，比如neuro。实际上我的理想形态就是neuro。但是我仍然开始这个项目，因为我想验证我的想法。

我的想法有几个：
- 事件流的形式组织prompt和输出
- 记忆的闪回

事件流，是这个项目的主要想法。所有的活动用事件表达，所有的文字也以事件流的形式。LLM的context被看作注意域（attention field， 和transformer的attention不是一个东西），外部的输入变成一个个事件往注意域填写，LLM的思考和反应也是一个事件。一个事件应该足够的小。它不可以是长篇大论，它不应该占据太多的注意空间，它应该要让各种事件能够及时地进入注意中。细碎和灵活是事件流的设计目的。事件流可以让各种输入及时地反映给LLM，也能让LLM做出即时的反应。但最主要的，它源于我另一个想法。

记忆的闪回是另一个主要想法，让记忆模块不断地根据当前注意力来选择相关的记忆，并植入到当前注意中。*我相信当前的AI Vtuber应该也能做到这一点，但我不确定它们具体怎么实现的，或许我应该调研一下*。为实现这点，记忆需要以非常灵活的方式组织起来。这种灵活性是时间上的灵活，我用少的时间可以提取较少的信息，或许是模糊且不完整的。我用更多的时间，就能提取更多信息，逐渐丰富和清晰。我们甚至可以决定什么部分的信息可以一带而过，哪些信息可以继续深入。

我之所以产生这个想法是因为claude code并没有表现出我想要的长期注意力，每次`/clear`之后如同换了一个人。一方面，提取记忆需要agent主动去搜索各种文档，而如果agent忘记去搜索，那么记忆就白白浪费了。我觉得这是很有可能的，它怎么知道什么概念之前出现过，值得去搜索呢？它只能在任务的一开始做一次记忆搜索，之后再也不会碰了。另一方面，memory的组织形式是markdown，各种信息强行排列成顺序结构，我觉得缺乏灵活性，限制了“联想”的能力。它只能十分艰难地从“失忆”前的日记搜索出相关的文件（我让它写进serena的memory中，claude本身的memory无法完成这事），全部读入后再挑出相关的部分。

## 总体架构
这个AI助手包含多个模块，它们以异步的形式交互。
- System：这是这个AI助手的最主要模块，它的功能是：
    - 管理注意域
    - 处理事件
    - 调度其他模块
    - 管理AI助手的运行状态
- Concious：这是AI助手的意识所在、灵魂所在。
    - 产生想法
    - 调用其他模块的功能（所有的模块都可以互相调用，但是Conciousy应该是最主要的）
- Memory：保存AI助手中产生的各种信息
    - 存储记忆
    - 搜索记忆
    - 即时闪回
- Terminal：这是AI助手和用户交互的地方。不过，这是AI的终端，不是用户的终端。
    - 显示用户的输入
    - 写入AI助手的反馈。
- Timer：报时，或者设置倒计时
- Internet：让AI助手上网。

## 事件/活动
*事件，也可以叫做活动（Activity），我更青睐后者，但这个文档暂时先用“事件”。*

一个事件应该包含：主体（subject），动作（verb）

基本上，事件可以有这么几类，它们并不互斥：
- UnderCouncious：“潜意识”的活动，不出现在注意域中，但是会出现在事件流中。
- WakeUp：当系统沉睡时，这类事件会将系统唤醒。

事件不是日志。事件是这个AI“大脑”里面产生的各种活动。日志是代码行为。

存储事件的有两个地方：
- 事件流：所有产生的事件，包括注意域中的
- 注意域：部分事件，不能是UnderConcious，且System筛选后的。

## System

这个模块是事件流、注意域的管理者，各个模块的协调者。负责管理其他模块、处理从它们发送的事件，管理注意区域。

### 管理其他模块

其他模块需要注册在System中。它们并且可以注册特定条件的事件。当遇到特定事件时，System会调用它相应的功能。

其他模块向system append事件，而system则直接调用这些模块的功能，不是发送事件。

### 处理事件

首先它需要管理不同模块的事件。不是所有事件都能进入注意域。System对每个模块都有focus值，越focus的模块可以准入更多的事件。每个模块的事件按照重要性排序，优先重要的事件进入，其余只会append在事件流中。

另外，当事件流出现被注册的事件，System需要响应，调用相应功能。

System本身也是模块，它也有功能：比如调整focus值。它也可以注册在自己身上。


### 管理注意域

注意拥有固定大小，当它满了，它要清空至特定大小。



### 产生事件
System本身的各种活动也会产生事件。比如flush注意域会产生事件，这个是“潜意识”事件。

不过有个原则：事件的响应不产生事件。


## Concious
这个模块负责保持意识，不断产生想法、和意图。

它能产生两类事件：
- think：
- intention

目前，这个模块基于LLM实现，所以我们说LLM-based Concious

LLM的context除了注意力域，还有一段始终存在的“自我意识”或者“自我存在”的prompt，用来告诉LLM“我是谁”、“这里是我的内部想法”，“我能感知什么”，“我能做什么”（拥有什么能力）。就好像任何时刻，我们能够感知自己的存在，有自我意识一样。

*这似乎和Claude Code的System Prompt一样？我要调研一下*
### 格式

我希望concious的内容，或者说LLM的prompt是它第一人称的叙述，是它的内心世界。我不希望把LLM当作agent的驾驶员，去操纵一个agent如何反映。或者说，我想想要的是现在llm的thinking mode。

我比较纠结的是，应该怎么去编排注意域：完全结构化还是尽量自然文本（伪结构化）？

完全结构化：用jsonl格式输入输出，不隐藏任何组件，完整展示各个模块
- 优势：方便解析。而且格式清晰易懂，LLM一看就会。
- 劣势：这种结构化的文本还能作为内心独白吗？它能够理解其中的连续性吗？

伪结构化：
- 完全的自然文本不可行，要有一定的结构化：
  - 体现出流的形式
  - 要方便解析出事件
- 尽量地隐藏其他模块，比如system。把各种事件表述成第一人称，表述成内部想法。
- 优势：语义上更加连贯，可以更容易推理、续写。而且或许LLM能表现得更自然。
- 劣势：解析更难，实现更难。





## Memory

它提供功能：
- 被动记忆：被System刷出注意力区域的内容，memory会被动记忆。
- 提取记忆：被动和主动
  - 被动/闪回：从当前注意力域中联想记忆中可能相关的内容
  - 主动：根据一点线索去记忆里查询、扩展



### 记忆图
*我觉得这个概念应该很成熟了，我应该调研、学习一下*

*似乎有个叫知识图谱的东西？*

这个想法的来源是我希望AI具有联想的能力，也就是“闪回”的功能。人在思考的时候，受到外界刺激的时候会闪回一些记忆：回想起一些事，但是有时只回想起模糊的、碎片的事，并不是完整的记忆。但是人要是主动去回忆，往往也能从这些模糊碎片不断地扩展、补充，逐渐拼凑成完整的记忆。

我想模拟这个过程，因此我想把记忆变成图，图的每一点也要足够的碎片、细小。记忆点之间有边连接。边上也有属性表示这个关系。

和事件一样，记忆点也有大小限制。太大的内容应该拆成多个记忆点。


### 结构存储

记忆模块不一定需要模仿人类，计算机本来就可以做得更好！比如说记忆结构化的数据时，它可以记得又快又好。

我希望记忆模块既有图存储（碎片但易于“联想”），也有结构存储（缺少关联，对结构化数据更方便）。它们两个不应该是孤立的，而是相互结合。这使得记忆模块可以通过“联想”把某些结构化记忆提取出来。

### 优先顺序

我希望记忆是有优先顺序的，比如时间和重要性（记忆强度）。并且可以自由控制搜索的时间，优先搜索出最近、最强的的记忆，但随着时间增加，也能回忆起更早、更弱的记忆。

### 独立管理

记忆是单独地模块，concious没法指示应该如何记忆、记忆什么内容，记忆点的关联之类的。concious能做的，就是多想。

记忆模块能够从自然语言中发现关键字，也能把提取出的记忆总结成自然语言。这其实也和concious解耦合了，使得concious不需要关心记忆的细节，也不关心记忆的实现。

## Terminal

想象一下AI助手正在使用一个terminal来和用户交流。

两个功能：
- 显示print：打印用户的输入给ai
- 打字type：发送内容给用户

然而，这和常见的terminal不同，它是异步的！用户可以一边跟ai说话，ai也可以在那说话。
  
需要一个cui。