# 概览

## 想法
这个项目尝试去构建一个有自主性的、持续存在的AI助手。

我觉得LLM模型的对话的交互方式让AI太被动了。用户去激活LLM，LLM便活跃一段时间。即便是各种agent，即便它们具有plan的能力，能够规划、制定todo，也只是让延长了活跃时间。一方面，LLM不会即时反应，除非你发送prompt，或者打断它。另一方面，它的长期记忆依然很差。

现在也有很多基于llm的实时对话模型，有很多ai vtuber，比如neuro。实际上我的理想形态就是neuro。但是我仍然开始这个项目，因为我想验证一种想法：如果不用以对话形式使用LLM，而是让LLM不断续写事件流/意识流，能否创造一个能自主、能持续存在的AI。


事件流，是这个项目的主要想法。所有的活动用事件表达，所有的文字也以事件流的形式。LLM的context被看作注意域（attention field， 和transformer的attention不是一个东西），外部的输入作为事件往注意域填写，LLM的思考和反应也是一个事件。

一个事件应该足够的小。它不可以是长篇大论，它不应该占据太多的注意空间，它应该要让各种事件能够及时地进入注意中。细碎和灵活是事件流的设计目的。

这个AI助手包含多个模块，它们以异步的形式交互。
- System：这是这个AI助手的最主要模块，它的功能是：
    - 管理注意域
    - 处理事件
    - 调度其他模块
    - 管理AI助手的运行状态
- Concious：这是AI助手的意识所在、灵魂所在。
    - 产生想法
    - 调用其他模块的功能（所有的模块都可以互相调用，但是Conciousy应该是最主要的）
- Memory：保存AI助手中产生的各种信息
    - 存储记忆
    - 搜索记忆
    - 即时闪回
- Terminal：这是AI助手和用户交互的地方。不过，这是AI的终端，不是用户的终端。
    - 显示用户的输入
    - 写入AI助手的反馈。
- Timer：报时，或者设置倒计时
- Internet：让AI助手上网。

## 事件/活动
*事件，也可以叫做活动（Activity），我更青睐后者，但这个文档暂时先用“事件”。*

一个事件应该包含：主体（subject），动作（verb）

基本上，事件可以有这么几类，它们并不互斥：
- UnderCouncious：“潜意识”的活动，不出现在注意域中，但是会出现在事件流中。
- WakeUp：当系统沉睡时，这类事件会将系统唤醒。

事件不是日志。事件是这个AI“大脑”里面产生的各种活动。日志是代码行为。

存储事件的有两个地方：
- 事件流：所有产生的事件，包括注意域中的
- 注意域：部分事件，不能是UnderConcious，且System筛选后的。

## System

这个模块是事件流、注意域的管理者，各个模块的协调者。负责管理其他模块、处理从它们发送的事件，管理注意区域。

### 管理其他模块

其他模块需要注册在System中。它们并且可以注册特定条件的事件。当遇到特定事件时，System会调用它相应的功能。

其他模块向system append事件，而system则直接调用这些模块的功能，不是发送事件。

### 处理事件

首先它需要管理不同模块的事件。不是所有事件都能进入注意域。System对每个模块都有focus值，越focus的模块可以准入更多的事件。每个模块的事件按照重要性排序，优先重要的事件进入，其余只会append在事件流中。

另外，当事件流出现被注册的事件，System需要响应，调用相应功能。

System本身也是模块，它也有功能：比如调整focus值。它也可以注册在自己身上。


### 管理注意域

注意拥有固定大小，当它满了，它要清空至特定大小。



### 产生事件
System本身的各种活动也会产生事件。比如flush注意域会产生事件，这个是“潜意识”事件。

不过有个原则：事件的响应不产生事件。


## Concious
这个模块负责保持意识，不断产生想法、和意图。

它能产生两类事件：
- think：
- intention



目前，这个模块基于LLM实现，所以我们说LLM-based Concious

LLM的context除了注意力域，还有一段始终存在的“自我意识”或者“自我存在”的prompt，用来告诉LLM“我是谁”、“这里是我的内部想法”，“我能感知什么”，“我能做什么”（拥有什么能力）。就好像任何时刻，我们能够感知自己的存在，有自我意识一样。

*这似乎和Claude Code的System Prompt一样？我要调研一下*
### 格式

我希望concious的内容，或者说LLM的prompt是它第一人称的叙述，是它的内心世界。我不希望把LLM当作agent的驾驶员，去操纵一个agent如何反映。

我比较纠结的是，应该怎么去编排注意域：完全结构化还是尽量自然文本（伪结构化）？

完全结构化：用jsonl格式输入输出，不隐藏任何组件，完整展示各个模块
- 优势：方便解析。而且格式清晰易懂，LLM一看就会。
- 劣势：这种结构化的文本还能作为内心独白吗？它能够理解其中的连续性吗？

伪结构化：
- 完全的自然文本不可行，要有一定的结构化：
  - 体现出流的形式，要方便解析
- 尽量地隐藏模块，





## Memory

它提供功能：
- 记忆：
  - 被动记忆：被System刷出注意力区域的内容，memory会被动记忆。
- 提取记忆：也包含被动和主动
  - 被动/闪回：从当前注意力域中联想记忆中可能相关的内容
  - 主动：根据一点线索去记忆里查询、扩展



### 记忆图
*我觉得这个概念应该很成熟了，我应该调研、学习一下*

*似乎有个叫知识图谱的东西？*

这个想法的来源是我希望AI具有联想的能力，也就是“闪回”的功能。人在思考的时候，受到外界刺激的时候会闪回一些记忆：回想起一些事，但是有时只回想起模糊的、碎片的事，并不是完整的记忆。但是人要是主动去回忆，往往也能从这些模糊碎片不断地扩展、补充，逐渐拼凑成完整的记忆。

我想模拟这个过程，因此我想把记忆变成图，图的每一点也要足够的碎片、细小，这样

记忆点有独一无二的label：
- label需要概括这段记忆
- label需要包含足够的信息来和其他记忆区分
  - 比如“cup”

记忆点之间有边连接。边上也有属性表示这个关系。

和事件一样，记忆点也有大小限制。太大的内容应该拆成多个记忆点。

记忆边的关联程度可以增强，不过是通过反复地记忆来强化。

### 结构存储

记忆模块不一定需要模仿人类，计算机本来就可以做得更好！比如说记忆结构化的数据时，它可以记得又快又好。

### 独立管理

记忆是单独地模块，concious没法指示应该如何记忆、记忆什么内容，记忆点的关联之类的。concious能做的，就是多想。

记忆模块能够从自然语言中发现关键字，也能把提取出的记忆总结成自然语言。这其实也和concious解耦合了，使得concious不需要关心记忆的细节，也不关心记忆的实现。

## Terminal

想象一下AI助手正在使用一个terminal来和用户交流。

两个功能：
- 显示print：打印用户的输入给ai
- 打字type：发送内容给用户

然而，这和常见的terminal不同，它是异步的！用户可以一边跟ai说话，ai也可以在那说话。
  
需要一个cui。